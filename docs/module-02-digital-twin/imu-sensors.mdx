---
id: imu-sensors
title: "Simulating IMU Sensors"
sidebar_label: "07: IMU"
sidebar_position: 7
description: "Configure IMU sensors in Gazebo with realistic bias, drift, and noise models for orientation estimation and sensor fusion."
keywords: [imu, accelerometer, gyroscope, noise, bias, drift, urdf, sdf]
sources:
  - "Open Robotics. (2023). IMU sensor. Gazebo. https://gazebosim.org/docs/fortress/sensors#imu"
  - "Open Robotics. (2023). SDF IMU sensor element. Gazebo. http://sdformat.org/spec?elem=sensor&ver=1.9"
  - "Open Source Robotics Foundation. (2023). Imu message. ROS 2 Humble. https://docs.ros.org/en/humble/p/sensor_msgs/interfaces/msg/Imu.html"
  - "Open Robotics. (2023). IMU noise model. Gazebo. https://gazebosim.org/api/sensors/7/classignition_1_1sensors_1_1ImuSensor.html"
learning_objectives:
  - Understand IMU sensor technology and its role in robotics
  - Configure IMU plugin with accelerometer and gyroscope parameters
  - Apply realistic noise models (bias, drift, Gaussian noise)
  - Interpret Imu message data in ROS 2
  - Visualize IMU orientation in RViz2
prerequisites: ["sensor-simulation-overview"]
estimated_time: "20 minutes"
---

# Simulating IMU Sensors

## 7.1 IMU Sensor Basics

An **Inertial Measurement Unit (IMU)** is a sensor that measures **linear acceleration** and **angular velocity** using two components:

1. **Accelerometer** (3-axis): Measures specific force (acceleration) along X, Y, Z axes. Includes gravitational acceleration (9.81 m/s²).
2. **Gyroscope** (3-axis): Measures angular velocity (rotation rate) around X, Y, Z axes in radians per second.

Some IMUs also include a **magnetometer** (compass) for absolute heading, but Gazebo's IMU sensor only simulates accelerometer + gyroscope.

### Why IMUs Matter in Robotics

IMUs are essential for:
- **State estimation**: Combining IMU data with other sensors (e.g., GPS, visual odometry) to estimate robot position and orientation
- **Sensor fusion**: Algorithms like Extended Kalman Filters (EKF) fuse IMU with wheel odometry for accurate localization
- **Stabilization**: Drones and legged robots use IMUs for balance control
- **Dead reckoning**: When GPS or cameras fail, IMUs provide short-term motion estimates

Unlike LiDAR or cameras, IMUs measure **ego-motion** (the robot's own movement), not the environment. They provide **high-frequency updates** (100-1000 Hz) but **drift over time** due to integration errors.

## 7.2 Gazebo IMU Plugin Configuration

Gazebo's `imu` sensor plugin simulates a 6-DOF (degrees of freedom) IMU by querying the physics engine for the sensor link's **linear acceleration** and **angular velocity** at each timestep (Open Robotics, 2023, IMU sensor documentation).

### Basic IMU Configuration (SDF)

```xml
<sensor name="imu" type="imu">
  <update_rate>100</update_rate>  <!-- 100 Hz update rate -->
  <topic>/imu/data</topic>  <!-- ROS 2 topic name -->

  <imu>
    <!-- Accelerometer configuration -->
    <angular_velocity>
      <x>
        <noise type="gaussian">
          <mean>0.0</mean>
          <stddev>0.001</stddev>  <!-- Gyro noise: 0.001 rad/s -->
        </noise>
      </x>
      <y>
        <noise type="gaussian">
          <mean>0.0</mean>
          <stddev>0.001</stddev>
        </noise>
      </y>
      <z>
        <noise type="gaussian">
          <mean>0.0</mean>
          <stddev>0.001</stddev>
        </noise>
      </z>
    </angular_velocity>

    <!-- Gyroscope configuration -->
    <linear_acceleration>
      <x>
        <noise type="gaussian">
          <mean>0.0</mean>
          <stddev>0.01</stddev>  <!-- Accel noise: 0.01 m/s² -->
        </noise>
      </x>
      <y>
        <noise type="gaussian">
          <mean>0.0</mean>
          <stddev>0.01</stddev>
        </noise>
      </y>
      <z>
        <noise type="gaussian">
          <mean>0.0</mean>
          <stddev>0.01</stddev>
        </noise>
      </z>
    </linear_acceleration>
  </imu>
</sensor>
```

**Key Parameters** (Open Robotics, 2023, SDF IMU sensor element documentation):
- **update_rate**: Measurement frequency (Hz). Typical IMUs: 100-1000 Hz. Higher rates enable better motion tracking.
- **angular_velocity**: Gyroscope measurements (rad/s). Measures rotation rates.
- **linear_acceleration**: Accelerometer measurements (m/s²). Includes gravity + robot acceleration.

**Note**: Gazebo IMUs automatically include gravity in the accelerometer reading. When the robot is stationary on flat ground, the Z-axis accelerometer reads approximately +9.81 m/s² (gravity pointing upward in the sensor frame).

## 7.3 IMU Noise Models: Bias, Drift, Random Walk

Real IMUs have **three types of errors** that simulation must capture:

### 1. Gaussian White Noise
Random noise on each measurement, modeled as Gaussian distribution. This is the most basic noise type.

**Accelerometer example**:
```xml
<noise type="gaussian">
  <mean>0.0</mean>
  <stddev>0.01</stddev>  <!-- 0.01 m/s² noise -->
</noise>
```

**Typical values** (Open Robotics, 2023, IMU noise model documentation):
- **Low-cost IMU** (e.g., MPU-6050): `stddev=0.05` m/s² (accel), `stddev=0.005` rad/s (gyro)
- **Mid-range IMU** (e.g., Bosch BNO055): `stddev=0.01` m/s² (accel), `stddev=0.001` rad/s (gyro)
- **High-end IMU** (e.g., Xsens MTi): `stddev=0.002` m/s² (accel), `stddev=0.0001` rad/s (gyro)

### 2. Bias (Constant Offset)
IMUs have a **constant offset** (bias) added to all measurements. This bias is different for each sensor unit and changes slowly with temperature.

**Example**: If gyro has +0.01 rad/s bias on X-axis, all X-axis readings will be 0.01 rad/s too high, even when stationary.

**SDF Configuration**:
```xml
<noise type="gaussian">
  <mean>0.01</mean>  <!-- 0.01 rad/s constant bias -->
  <stddev>0.001</stddev>  <!-- Plus Gaussian noise -->
  <bias_mean>0.01</bias_mean>  <!-- Bias changes slowly over time -->
  <bias_stddev>0.0001</bias_stddev>  <!-- Bias drift rate -->
</noise>
```

**Impact**: When integrating gyro readings to estimate orientation, constant bias causes **linear drift** (error grows linearly over time). After 60 seconds with 0.01 rad/s bias, orientation error = 0.6 radians (34°).

### 3. Random Walk (Bias Drift)
Bias itself **drifts randomly** over time (like Brownian motion). This is modeled as a random walk process.

**Parameters**:
- **bias_mean**: Initial bias value
- **bias_stddev**: Rate of bias change (bias random walk coefficient)

**Example**: Accelerometer bias starts at 0 m/s², but after 10 minutes may drift to ±0.05 m/s² due to temperature changes.

**Why it matters**: Sensor fusion algorithms (EKF, UKF) estimate and compensate for bias in real-time, but they need realistic bias models in simulation to work correctly.

## 7.4 Adding IMU to Robot Model

Here's a complete URDF example adding an IMU to a robot:

```xml
<?xml version="1.0"?>
<robot name="robot_with_imu" xmlns:xacro="http://www.ros.org/wiki/xacro">

  <!-- Base link -->
  <link name="base_link">
    <visual>
      <geometry>
        <box size="0.5 0.3 0.2"/>
      </geometry>
    </visual>
    <collision>
      <geometry>
        <box size="0.5 0.3 0.2"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="10.0"/>
      <inertia ixx="0.1" iyy="0.1" izz="0.1" ixy="0" ixz="0" iyz="0"/>
    </inertial>
  </link>

  <!-- IMU link (usually inside robot body) -->
  <link name="imu_link">
    <inertial>
      <mass value="0.001"/>  <!-- IMUs are very light -->
      <inertia ixx="0.000001" iyy="0.000001" izz="0.000001" ixy="0" ixz="0" iyz="0"/>
    </inertial>
  </link>

  <!-- Joint connecting base to IMU (fixed, at robot center) -->
  <joint name="imu_joint" type="fixed">
    <parent link="base_link"/>
    <child link="imu_link"/>
    <origin xyz="0 0 0" rpy="0 0 0"/>  <!-- IMU at robot center of mass -->
  </joint>

  <!-- Gazebo IMU sensor plugin -->
  <gazebo reference="imu_link">
    <sensor name="imu_sensor" type="imu">
      <update_rate>100</update_rate>
      <topic>/imu/data</topic>

      <imu>
        <angular_velocity>
          <x>
            <noise type="gaussian">
              <mean>0.0</mean>
              <stddev>0.001</stddev>
              <bias_mean>0.005</bias_mean>
              <bias_stddev>0.0001</bias_stddev>
            </noise>
          </x>
          <y>
            <noise type="gaussian">
              <mean>0.0</mean>
              <stddev>0.001</stddev>
              <bias_mean>0.005</bias_mean>
              <bias_stddev>0.0001</bias_stddev>
            </noise>
          </y>
          <z>
            <noise type="gaussian">
              <mean>0.0</mean>
              <stddev>0.001</stddev>
              <bias_mean>0.005</bias_mean>
              <bias_stddev>0.0001</bias_stddev>
            </noise>
          </z>
        </angular_velocity>

        <linear_acceleration>
          <x>
            <noise type="gaussian">
              <mean>0.0</mean>
              <stddev>0.01</stddev>
              <bias_mean>0.02</bias_mean>
              <bias_stddev>0.001</bias_stddev>
            </noise>
          </x>
          <y>
            <noise type="gaussian">
              <mean>0.0</mean>
              <stddev>0.01</stddev>
              <bias_mean>0.02</bias_mean>
              <bias_stddev>0.001</bias_stddev>
            </noise>
          </y>
          <z>
            <noise type="gaussian">
              <mean>0.0</mean>
              <stddev>0.01</stddev>
              <bias_mean>0.02</bias_mean>
              <bias_stddev>0.001</bias_stddev>
            </noise>
          </z>
        </linear_acceleration>
      </imu>
    </sensor>
  </gazebo>

</robot>
```

### Key URDF Concepts:
- **imu_link**: IMU sensor is attached to a separate link (often with negligible mass)
- **imu_joint**: Fixed joint at robot's center of mass (origin = 0,0,0 relative to base_link)
- **Noise configuration**: Separate noise models for each axis (X, Y, Z) of gyro and accel

### Loading and Verifying IMU

```bash
# Launch robot in Gazebo
ros2 launch my_robot_description robot.launch.py

# Verify IMU topic is publishing
ros2 topic list | grep imu
# Output: /imu/data

ros2 topic hz /imu/data
# Output: average rate: 100.000

# Echo IMU data (see raw measurements)
ros2 topic echo /imu/data --once
```

## 7.5 Understanding IMU Data in ROS 2

The `sensor_msgs/msg/Imu` message contains (Open Source Robotics Foundation, 2023, Imu message documentation):

```yaml
Header header  # Timestamp and frame_id
Quaternion orientation  # 3D orientation (estimated, NOT raw from IMU)
float64[9] orientation_covariance  # Uncertainty in orientation
Vector3 angular_velocity  # Gyroscope: rotation rates (rad/s)
float64[9] angular_velocity_covariance  # Gyro uncertainty
Vector3 linear_acceleration  # Accelerometer: accel + gravity (m/s²)
float64[9] linear_acceleration_covariance  # Accel uncertainty
```

### Important Fields:

**1. orientation (Quaternion)**:
- In Gazebo, this is **automatically computed** from the robot's true orientation (not from integrating gyro data).
- Real IMUs may not provide orientation (raw gyro/accel only). Orientation estimation requires sensor fusion algorithms.

**2. angular_velocity (Vector3)**:
- **X**: Roll rate (rotation around forward axis)
- **Y**: Pitch rate (rotation around left-right axis)
- **Z**: Yaw rate (rotation around up-down axis)
- **Units**: rad/s

**3. linear_acceleration (Vector3)**:
- Measures **specific force** = robot acceleration + gravity
- **Stationary robot on flat ground**: `linear_acceleration.z ≈ 9.81 m/s²` (gravity)
- **Robot accelerating forward**: `linear_acceleration.x > 0` (plus gravity component if tilted)

## 7.6 Visualizing IMU Orientation in RViz2

RViz2 can display IMU orientation as a 3D coordinate frame.

### Step 1: Add TF Display

```bash
rviz2
```

In RViz2:
1. **Set Fixed Frame**: `base_link` or `world`
2. **Add TF Display**:
   - Click **Add** → **TF**
   - This shows all coordinate frames, including `imu_link`
3. **Adjust TF Settings**:
   - **Show Names**: Enable to see frame labels
   - **Marker Scale**: Increase to 0.3 for visibility

### Step 2: Verify IMU Frame

The `imu_link` frame should appear at the IMU's position (robot center if you followed Section 7.4).

- **Red axis** = X (forward)
- **Green axis** = Y (left)
- **Blue axis** = Z (up)

As the robot rotates in Gazebo, the IMU frame rotates accordingly.

### Step 3: Monitor Orientation Data

```bash
# Print quaternion orientation
ros2 topic echo /imu/data --field orientation

# Convert quaternion to Euler angles (roll, pitch, yaw)
# Use Python or a quaternion library like `tf_transformations`
```

## 7.7 Practical Exercise: Gyro Integration for Yaw Estimation

**Objective**: Estimate robot's yaw (heading) by integrating gyroscope Z-axis measurements.

### ROS 2 Node (Python):

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Imu
import math

class YawEstimator(Node):
    def __init__(self):
        super().__init__('yaw_estimator')
        self.subscription = self.create_subscription(
            Imu,
            '/imu/data',
            self.imu_callback,
            10
        )
        self.yaw = 0.0  # Estimated yaw in radians
        self.last_time = None
        self.get_logger().info('Yaw estimator started (integrating gyro Z)')

    def imu_callback(self, msg):
        # Get current time
        current_time = msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9

        if self.last_time is not None:
            # Time delta (seconds)
            dt = current_time - self.last_time

            # Integrate angular velocity Z (yaw rate)
            gyro_z = msg.angular_velocity.z
            self.yaw += gyro_z * dt

            # Normalize yaw to [-π, π]
            self.yaw = math.atan2(math.sin(self.yaw), math.cos(self.yaw))

            # Log estimated yaw in degrees
            yaw_deg = math.degrees(self.yaw)
            self.get_logger().info(f'Estimated yaw: {yaw_deg:.2f}° (gyro_z: {gyro_z:.4f} rad/s)')

        self.last_time = current_time

def main():
    rclpy.init()
    node = YawEstimator()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Test the Exercise:

```bash
# Terminal 1: Launch Gazebo with robot
ros2 launch my_robot_description robot.launch.py

# Terminal 2: Run yaw estimator
ros2 run my_robot_package yaw_estimator

# Terminal 3: Rotate robot in Gazebo (use teleop or drag robot)
ros2 run teleop_twist_keyboard teleop_twist_keyboard

# Observe yaw estimate in Terminal 2
# Note: Yaw will drift over time due to gyro bias!
```

**Expected Behavior**:
- Rotating robot clockwise → Yaw decreases
- Rotating robot counter-clockwise → Yaw increases
- Over time, yaw estimate drifts away from true yaw due to bias and noise (this is why sensor fusion with other sensors is needed!)

---

**Key Takeaways**:
- IMUs measure linear acceleration and angular velocity at high frequency (100-1000 Hz)
- Configure realistic noise models: Gaussian white noise, bias, and bias drift (random walk)
- IMU data must be fused with other sensors (odometry, GPS, vision) to prevent drift
- Gazebo IMU plugin automatically includes gravity in accelerometer readings
- Visualize IMU orientation in RViz2 using TF display

Phase 5 complete! You can now simulate all three critical sensors (LiDAR, depth cameras, IMU) for robotics perception and state estimation.
