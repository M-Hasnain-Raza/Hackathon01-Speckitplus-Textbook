---
id: lidar-sensors
title: "Simulating LiDAR Sensors"
sidebar_label: "05: LiDAR"
sidebar_position: 5
description: "Configure 2D/3D LiDAR sensors in Gazebo with realistic noise models, integrate with ROS 2, and visualize scan data in RViz2."
keywords: [lidar, laser, ray sensor, noise, urdf, sdf, laserscan]
sources:
  - "Open Robotics. (2023). gpu_lidar sensor. Gazebo. https://gazebosim.org/docs/fortress/sensors#gpu-lidar"
  - "Open Source Robotics Foundation. (2023). LaserScan message. ROS 2 Humble. https://docs.ros.org/en/humble/p/sensor_msgs/interfaces/msg/LaserScan.html"
  - "Open Robotics. (2023). SDF sensor element. Gazebo. http://sdformat.org/spec?elem=sensor"
  - "Open Robotics. (2023). Sensor noise. Gazebo. https://gazebosim.org/api/sensors/7/noise.html"
learning_objectives:
  - Understand LiDAR technology and its role in robotics
  - Configure gpu_lidar sensor plugin in URDF/SDF
  - Apply realistic noise models to LiDAR range measurements
  - Visualize LaserScan data in RViz2 for debugging
prerequisites: ["sensor-simulation-overview"]
estimated_time: "25 minutes"
---

# Simulating LiDAR Sensors

## 5.1 LiDAR Technology Overview

**LiDAR** (Light Detection and Ranging) is a remote sensing technology that measures distances by emitting laser pulses and timing their reflections. In robotics, LiDAR sensors are indispensable for:

- **2D Navigation**: Mobile robots use 2D LiDAR (horizontal plane scans) for obstacle avoidance and SLAM (Simultaneous Localization and Mapping)
- **3D Mapping**: Autonomous vehicles and drones use 3D LiDAR (multi-plane or spinning sensors) to build detailed environmental maps
- **Object Detection**: High-resolution LiDAR enables detection and classification of objects (pedestrians, vehicles, furniture)

LiDAR sensors work by:
1. **Emitting** a laser pulse in a specific direction
2. **Measuring** the time-of-flight (ToF) until the pulse reflects back
3. **Calculating** distance: `distance = (speed_of_light × time) / 2`
4. **Repeating** this process across a range of angles (e.g., 0° to 360° for 2D, or multiple vertical planes for 3D)

The result is a **point cloud** or **scan**: a set of (angle, range) pairs representing obstacle distances at each scanned direction. In ROS 2, 2D LiDAR data is published as `sensor_msgs/msg/LaserScan` messages, while 3D LiDAR uses `sensor_msgs/msg/PointCloud2` (Open Source Robotics Foundation, 2023, LaserScan message documentation).

## 5.2 Gazebo Ray Sensor Plugin Configuration

Gazebo Fortress uses the **gpu_lidar** sensor plugin to simulate LiDAR via GPU-accelerated **ray casting** (Open Robotics, 2023, gpu_lidar sensor documentation). Instead of physically emitting light, the plugin casts virtual rays through the 3D scene and checks for collisions with obstacles.

### Basic gpu_lidar Configuration (SDF)

Here's a minimal LiDAR sensor definition in SDF (Simulation Description Format):

```xml
<sensor name="lidar" type="gpu_lidar">
  <update_rate>10</update_rate>  <!-- Scan frequency: 10 Hz -->
  <topic>/scan</topic>  <!-- Gazebo topic name -->

  <lidar>
    <scan>
      <horizontal>
        <samples>360</samples>  <!-- Number of rays per scan -->
        <resolution>1</resolution>  <!-- Angular resolution multiplier -->
        <min_angle>-3.14159</min_angle>  <!-- -180 degrees -->
        <max_angle>3.14159</max_angle>   <!-- +180 degrees -->
      </horizontal>
    </scan>

    <range>
      <min>0.1</min>  <!-- Minimum detection range (m) -->
      <max>10.0</max>  <!-- Maximum detection range (m) -->
      <resolution>0.01</resolution>  <!-- Range resolution (m) -->
    </range>
  </lidar>
</sensor>
```

**Key Parameters** (Open Robotics, 2023, SDF sensor element documentation):
- **update_rate**: How often the sensor publishes (Hz). Typical: 10-40 Hz for 2D LiDAR.
- **samples**: Number of range measurements per scan (360 = 1° angular resolution for 360° scan).
- **min_angle / max_angle**: Horizontal field-of-view (radians). Use `-π` to `+π` for full 360°.
- **min / max range**: Detection limits. Objects closer than `min` or farther than `max` are ignored.

## 5.3 Key Parameters: Range, Resolution, Scan Rate

### Angular Resolution
Angular resolution determines how finely the sensor samples the environment. It's calculated as:

```
angular_resolution = (max_angle - min_angle) / samples
```

**Example**: 360 samples over 360° → 1° per ray.

**Trade-off**: Higher resolution (more samples) provides finer detail but increases computational cost and data size. For 2D navigation, 360-720 samples is standard. For 3D LiDAR, you may need 10,000+ samples per scan.

### Range Resolution
Range resolution (`<resolution>` in `<range>`) specifies the precision of distance measurements. A value of 0.01 means distances are reported in 1 cm increments.

**Real-world analogy**: High-end Velodyne LiDAR has ±2 cm accuracy. Budget sensors may have ±5 cm.

### Scan Rate (Update Rate)
The update rate determines how often the sensor publishes. For mobile robots, 10-20 Hz is typical (matching real Hokuyo or SICK LiDAR). Faster rates (30-40 Hz) are used for high-speed navigation.

**ROS 2 Topic Throughput**:
```
data_rate (MB/s) = (samples × 4 bytes × update_rate) / 1,000,000
```
For 360 samples at 10 Hz: ~0.014 MB/s (negligible). For 10,000 samples at 30 Hz: ~1.2 MB/s (significant).

## 5.4 Adding LiDAR to URDF/SDF Robot Model

To add a LiDAR sensor to a robot in Gazebo, you attach it to a **link** in the robot's URDF (Unified Robot Description Format) file. The sensor will move with that link.

### Complete URDF Example: Adding 2D LiDAR

```xml
<?xml version="1.0"?>
<robot name="robot_with_lidar" xmlns:xacro="http://www.ros.org/wiki/xacro">

  <!-- Base link (robot body) -->
  <link name="base_link">
    <visual>
      <geometry>
        <box size="0.5 0.3 0.2"/>
      </geometry>
    </visual>
    <collision>
      <geometry>
        <box size="0.5 0.3 0.2"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="10.0"/>
      <inertia ixx="0.1" iyy="0.1" izz="0.1" ixy="0" ixz="0" iyz="0"/>
    </inertial>
  </link>

  <!-- LiDAR link (sensor mounting point) -->
  <link name="lidar_link">
    <visual>
      <geometry>
        <cylinder radius="0.05" length="0.07"/>
      </geometry>
      <material name="black"/>
    </visual>
    <collision>
      <geometry>
        <cylinder radius="0.05" length="0.07"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="0.1"/>
      <inertia ixx="0.0001" iyy="0.0001" izz="0.0001" ixy="0" ixz="0" iyz="0"/>
    </inertial>
  </link>

  <!-- Joint connecting base to LiDAR (fixed) -->
  <joint name="lidar_joint" type="fixed">
    <parent link="base_link"/>
    <child link="lidar_link"/>
    <origin xyz="0.2 0 0.15" rpy="0 0 0"/>  <!-- Mount LiDAR on front-top of robot -->
  </joint>

  <!-- Gazebo-specific sensor plugin -->
  <gazebo reference="lidar_link">
    <sensor name="lidar" type="gpu_lidar">
      <update_rate>10</update_rate>
      <topic>/scan</topic>
      <lidar>
        <scan>
          <horizontal>
            <samples>360</samples>
            <resolution>1</resolution>
            <min_angle>-3.14159</min_angle>
            <max_angle>3.14159</max_angle>
          </horizontal>
        </scan>
        <range>
          <min>0.1</min>
          <max>10.0</max>
          <resolution>0.01</resolution>
        </range>
      </lidar>
    </sensor>
  </gazebo>

</robot>
```

### Key URDF Concepts:
- **lidar_link**: A separate link represents the sensor's physical body (visualized as a small cylinder).
- **lidar_joint**: A fixed joint attaches the LiDAR to `base_link` at position `(0.2, 0, 0.15)` relative to the base.
- **gazebo reference**: The `<gazebo reference="lidar_link">` block tells Gazebo to attach the sensor plugin to this link.

### Loading the URDF in Gazebo

```bash
# Spawn robot in Gazebo (assuming you have a launch file)
ros2 launch my_robot_description robot.launch.py

# Verify the sensor topic is publishing
ros2 topic list | grep scan
# Output: /scan

ros2 topic hz /scan
# Output: average rate: 10.000
```

## 5.5 Configuring LiDAR Noise

Real LiDAR sensors have measurement noise due to:
- **Reflectivity variations**: Dark or glossy surfaces return weaker signals, increasing range error.
- **Ambient light**: Sunlight can interfere with laser pulses.
- **Multi-path reflections**: Laser bounces off multiple surfaces before returning.

To simulate realistic noise, Gazebo supports **Gaussian noise** on range measurements (Open Robotics, 2023, Sensor Noise documentation).

### Adding Gaussian Noise to LiDAR

```xml
<sensor name="lidar" type="gpu_lidar">
  <update_rate>10</update_rate>
  <topic>/scan</topic>
  <lidar>
    <scan>
      <!-- ... scan configuration ... -->
    </scan>
    <range>
      <min>0.1</min>
      <max>10.0</max>
      <resolution>0.01</resolution>
    </range>
    <!-- Noise model: Gaussian with 2 cm standard deviation -->
    <noise>
      <type>gaussian</type>
      <mean>0.0</mean>
      <stddev>0.02</stddev>  <!-- 2 cm noise -->
    </noise>
  </lidar>
</sensor>
```

**Interpretation**:
- Each range measurement is perturbed by random noise drawn from a normal distribution: `N(0, 0.02)`.
- **68%** of measurements will be within ±2 cm of true range.
- **95%** will be within ±4 cm.

**Tuning Noise**:
- **Low-cost LiDAR** (e.g., Hokuyo URG-04LX): `stddev=0.03` (3 cm)
- **Mid-range LiDAR** (e.g., SICK TIM561): `stddev=0.02` (2 cm)
- **High-end LiDAR** (e.g., Velodyne VLP-16): `stddev=0.01` (1 cm)

Always validate noise models by comparing simulated and real sensor data histograms.

## 5.6 Visualizing LaserScan Data in RViz2

RViz2 provides a **LaserScan** display type for visualizing 2D LiDAR data.

### Step 1: Launch RViz2

```bash
rviz2
```

### Step 2: Configure RViz2

1. **Set Fixed Frame**: Click the dropdown next to "Fixed Frame" and select `base_link` (or `lidar_link` if you want the view to rotate with the sensor).
2. **Add LaserScan Display**:
   - Click **Add** (bottom left)
   - Select **By topic** → `/scan` → **LaserScan**
   - Click **OK**
3. **Configure Display**:
   - **Size**: Increase to 0.05 for better visibility
   - **Color**: Set to "Flat Color" or "Intensity" (if your LiDAR provides intensity data)
   - **Decay Time**: Set to 0.5 seconds to see scan history

### Step 3: Verify Scan Data

Move obstacles in Gazebo (e.g., drag a box near the robot) and observe the LaserScan points update in RViz2. Points should appear where obstacles intersect the LiDAR's horizontal plane.

**Common Issues**:
- **No points visible**: Check that `Fixed Frame` matches your robot's base frame.
- **Points not updating**: Verify `/scan` topic is publishing with `ros2 topic hz /scan`.
- **Points at wrong height**: Ensure LiDAR link's Z-position in URDF matches expected height.

### Step 4: Compare Clean vs. Noisy Scans

To visualize the effect of noise:
1. Launch robot without noise (remove `<noise>` block from URDF)
2. Record a bag: `ros2 bag record /scan`
3. Add noise to URDF (e.g., `stddev=0.03`)
4. Launch robot again and record another bag
5. Play both bags simultaneously and compare in RViz2

You should see more "fuzziness" in the noisy scan, especially at longer ranges.

## 5.7 Practical Exercise: Obstacle Detection with LiDAR

**Objective**: Create a simple obstacle detector that warns when objects are closer than 1 meter.

### ROS 2 Node (Python):

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan

class ObstacleDetector(Node):
    def __init__(self):
        super().__init__('obstacle_detector')
        self.subscription = self.create_subscription(
            LaserScan,
            '/scan',
            self.scan_callback,
            10
        )
        self.get_logger().info('Obstacle detector started')

    def scan_callback(self, msg):
        # Find minimum range in front 90-degree arc (indices 90-270 for 360-sample scan)
        front_ranges = msg.ranges[90:270]
        min_distance = min([r for r in front_ranges if r > msg.range_min and r < msg.range_max])

        if min_distance < 1.0:
            self.get_logger().warn(f'Obstacle detected at {min_distance:.2f}m!')
        else:
            self.get_logger().info(f'Clear ahead (min distance: {min_distance:.2f}m)')

def main():
    rclpy.init()
    node = ObstacleDetector()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Test the Exercise:

```bash
# Terminal 1: Launch Gazebo with your robot
ros2 launch my_robot_description robot.launch.py

# Terminal 2: Run obstacle detector
ros2 run my_robot_package obstacle_detector

# Terminal 3: Visualize in RViz2
rviz2

# In Gazebo, drag obstacles toward the robot and observe warnings in Terminal 2
```

---

**Key Takeaways**:
- Gazebo's `gpu_lidar` plugin uses ray casting to simulate LiDAR sensors
- Configure angular resolution, range limits, and update rate based on real sensor specs
- Add Gaussian noise to match real-world sensor characteristics
- Visualize LaserScan data in RViz2 for debugging perception algorithms
- LiDAR simulation enables algorithm-in-the-loop testing before hardware deployment

Next, we'll configure depth cameras for 3D perception.
